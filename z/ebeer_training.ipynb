{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3kQr3NGfHo7q"
      },
      "source": [
        "# Via google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjZpMphNjpRn",
        "outputId": "1218bd84-f6ee-46dd-880a-697afae23259"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wZNCrDKJkN17"
      },
      "source": [
        "# Obtenção da base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i03owIp6HfLU",
        "outputId": "2b8a5717-b7fa-4206-9ad0-33b549cb06f8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "!git clone https://github.com/Diegoomal/ebeer_dataset.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XzOHMSw3kSR0"
      },
      "source": [
        "# Instalação de pacotes extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI3s1B5GkXcQ",
        "outputId": "48d71c97-8a50-4c4d-969d-af933e60333e"
      },
      "outputs": [],
      "source": [
        "# ! pip install imutils --quiet\n",
        "# ! pip install adabelief-tf --quiet\n",
        "# ! pip install mlflow --quiet"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "K96b5_hBkZro"
      },
      "source": [
        "# Importação dos modulos necessários"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g_weosBMkdbJ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m listdir\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mimport\u001b[39;00m isfile, join\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import mlflow\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "from adabelief_tf import AdaBeliefOptimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from datetime import datetime\n",
        "import random as python_random\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import (Activation, Dropout, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input, AveragePooling2D)\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3qlqc-P6rB1n"
      },
      "source": [
        "# Configuração do MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0coRum4QrFFx"
      },
      "outputs": [],
      "source": [
        "# MLFLOW_TRACKING_USERNAME = 'diego.maldonado'\n",
        "# MLFLOW_TRACKING_PASSWORD = 'd431b7b196e28028b386d497062f5ecad26855ed'\n",
        "# MLFLOW_TRACKING_URI = 'https://dagshub.com/diego.maldonado/proj_integrado_cnn_cerveja.mlflow'\n",
        "\n",
        "# os.environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n",
        "# os.environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n",
        "\n",
        "# mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "\n",
        "# mlflow.tensorflow.autolog(log_models=True, log_input_examples=True, log_model_signatures=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nJSTbUZhkvZb"
      },
      "source": [
        "# Definição de funções adicionais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qIC7Slcuk1sN"
      },
      "outputs": [],
      "source": [
        "def read_data_files(root, folder, sub_folder, file_name):\n",
        "  with open(os.path.join(root, folder, sub_folder, file_name)) as f:\n",
        "    files_names = [line.replace('\\n','') for line in f.readlines()]\n",
        "  return files_names\n",
        "\n",
        "def read_files_names(root, folder):\n",
        "  return os.listdir(os.path.join(root, folder))\n",
        "\n",
        "def read_image(root, folder, file_name) -> None:\n",
        " return tf.keras.utils.load_img(\n",
        "      os.path.join(root, folder, file_name),\n",
        "      grayscale=False,\n",
        "      color_mode='rgb',\n",
        "      target_size=None,\n",
        "      interpolation='nearest'\n",
        "  )\n",
        "\n",
        "def reset_seeds():\n",
        "   np.random.seed(123) \n",
        "   python_random.seed(123)\n",
        "   tf.random.set_seed(1234)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BNXXq5yDk8Xn"
      },
      "source": [
        "# Leitura do dataset e atribuição às respectivas variáveis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30vLgABilCTB"
      },
      "outputs": [],
      "source": [
        "width = 128\n",
        "height = 128\n",
        "channels = 3\n",
        "\n",
        "size = (height, width)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_2fT7m0nDOL"
      },
      "outputs": [],
      "source": [
        "datasetPath = '/src/ebeer_dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w1xkIx5wj3FT"
      },
      "outputs": [],
      "source": [
        "# filePath = 'skol_lata_350ml'\n",
        "\n",
        "# filesNames = read_files_names(datasetPath, filePath)\n",
        "\n",
        "# train_data_skol = [np.array(image).astype('float32')/255 for image in [read_image(datasetPath, filePath, image_name).resize(size) for image_name in filesNames]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_YSdjQNi9TI"
      },
      "outputs": [],
      "source": [
        "# filePath = 'brahma_duplo_malte_lata_350ml'\n",
        "\n",
        "# filesNames = read_files_names(datasetPath, filePath)\n",
        "\n",
        "# train_data_brahma = [np.array(image).astype('float32')/255 for image in [read_image(datasetPath, filePath, image_name).resize(size) for image_name in filesNames]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2DI1sfujkP7"
      },
      "outputs": [],
      "source": [
        "# filePath = 'heiniken_lata_350ml'\n",
        "\n",
        "# filesNames = read_files_names(datasetPath, filePath)\n",
        "\n",
        "# train_data_heiniken = [np.array(image).astype('float32')/255 for image in [read_image(datasetPath, filePath, image_name).resize(size) for image_name in filesNames]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuHBJKgYSafV"
      },
      "outputs": [],
      "source": [
        "# escapes = [\".git\", \"tests\", \"README.md\"]\n",
        "\n",
        "# for index, currentpath in enumerate(os.listdir(datasetPath), start=0):\n",
        "\n",
        "#   # data not interest dir's for training\n",
        "#   if (escapes.__contains__(currentpath)):\n",
        "#     continue\n",
        "\n",
        "#   print(index+1, '/', len(os.listdir(datasetPath)), '- diretorio:', currentpath)\n",
        "\n",
        "#   # meatada.json\n",
        "\n",
        "#   # verify if contains 'metadata.json' file\n",
        "#   path_json = os.path.join(datasetPath, currentpath, \"metadata.json\")\n",
        "#   if (os.path.exists(path_json)):\n",
        "#     print(\"metada exists\")\n",
        "#   else:\n",
        "#     break\n",
        "\n",
        "#   # images\n",
        "\n",
        "#   path_imgs = os.path.join(datasetPath, currentpath)\n",
        "#   filesname = read_files_names(datasetPath, path_imgs)\n",
        "\n",
        "#   # verify if contains images at dir\n",
        "#   if (len(filesname) > 0):\n",
        "#     print(\"images exists\")\n",
        "#   elif (len(filesname) == 0):\n",
        "#     print(\"images not exists\")\n",
        "#     break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uqfKc__BjWrq"
      },
      "source": [
        "## data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bu-uT830R8GY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'skimage'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskimage\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
          ]
        }
      ],
      "source": [
        "import skimage\n",
        "print(skimage.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skimage import io, img_as_ubyte\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "from skimage.util import random_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9-Mai5hSAtB"
      },
      "outputs": [],
      "source": [
        "def rotation_anti_clockwise(image):\n",
        "  angle = random.randint(0, 180)\n",
        "  return rotate(image, angle)\n",
        "\n",
        "def rotation_clockwise(image):\n",
        "  angle = random.randint(0, 180)\n",
        "  return rotate(image, -angle)\n",
        "\n",
        "def h_flip(image):\n",
        "  return np.fliplr(image)\n",
        "\n",
        "def v_flip(image):\n",
        "  return np.flipud(image)\n",
        "\n",
        "def brightness(image):\n",
        "  bright = np.ones(image.shape, dtype=\"uint8\") * 70\n",
        "  brightincrease = cv2.add(image, bright)\n",
        "  return brightincrease\n",
        "\n",
        "def blur_img(image):\n",
        "  k_size = random.randrange(1, 10, 2)\n",
        "  img_blur = cv2.medianBlur(image, k_size)\n",
        "  return img_blur\n",
        "\n",
        "def noise_img(image):\n",
        "  return random_noise(image)\n",
        "\n",
        "def zoom(image):\n",
        "  zoom_value = random.random()\n",
        "  hidth, width = image.shape[:2]\n",
        "  h_taken = int(zoom_value*hidth)\n",
        "  w_taken = int(zoom_value*width)\n",
        "  h_start = random.randint(0, hidth-h_taken)\n",
        "  w_start = random.randint(0, width-w_taken)\n",
        "  image = image[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n",
        "  image = cv2.resize(image, (hidth, width), cv2.INTER_CUBIC)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6utdo1_-SDcu"
      },
      "outputs": [],
      "source": [
        "transformations = {\n",
        "  'rotation_anti_clockwise': rotation_anti_clockwise,\n",
        "  'rotation_clockwise': rotation_clockwise,\n",
        "  'brightness': brightness,\n",
        "  'blur_img': blur_img,\n",
        "  'noise': noise_img,\n",
        "  'h_flip': h_flip,\n",
        "  'v_flip': v_flip,\n",
        "  'zoom': zoom\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "mxtspqSydoMY",
        "outputId": "cb87787c-f593-4721-dc8f-cd475b112f3e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "import datetime\n",
        "\n",
        "escapes = [\".git\", \"tests\", \"README.md\"]\n",
        "\n",
        "for index, currentpath in enumerate(os.listdir(datasetPath), start=0):\n",
        "\n",
        "  # data not interest dir's for training\n",
        "  if (escapes.__contains__(currentpath)):\n",
        "    continue\n",
        "\n",
        "  print(index+1, '/', len(os.listdir(datasetPath)), '- diretorio:', currentpath)\n",
        "\n",
        "  filesname = read_files_names(datasetPath, currentpath)\n",
        "  filesname.remove(\"metadata.json\")\n",
        "\n",
        "  # images = [read_image(datasetPath, currentpath, image_name) for image_name in filesname]\n",
        "  # print('len(images):', len(images))\n",
        "\n",
        "  for i, filename in enumerate(filesname, start=0):\n",
        "    for j, transformation in enumerate(list(transformations), start=0):\n",
        "\n",
        "      image_source = read_image(datasetPath, currentpath, filename) \n",
        "\n",
        "      image_transformed = transformations[transformation](image_source)\n",
        "      image_transformed = img_as_ubyte(image_transformed)\n",
        "      image_transformed = cv2.cvtColor(image_transformed, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      cv2.imwrite(\n",
        "          os.path.join(\n",
        "              datasetPath, \n",
        "              currentpath,\n",
        "              str(datetime.datetime.now().timestamp()).replace('.', '_') + \".jpg\"\n",
        "          ),\n",
        "          image_transformed\n",
        "      )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubB3lRvjevF"
      },
      "source": [
        "## dados disponiveis para treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "tCtzUZlcI3X8",
        "outputId": "52300483-8249-4ac0-a46f-a50cb010b3ee"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "# import json\n",
        "# import datetime\n",
        "\n",
        "# n_neuron_out = 0\n",
        "\n",
        "# metadatas = []\n",
        "# escapes = [\".git\", \"tests\", \"README.md\"]\n",
        "\n",
        "# for index, currentpath in enumerate(os.listdir(datasetPath), start=0):\n",
        "\n",
        "#   # data not interest dir's for training\n",
        "#   if (escapes.__contains__(currentpath)):\n",
        "#     continue\n",
        "\n",
        "#   print(index+1, '/', len(os.listdir(datasetPath)), '- diretorio:', currentpath)\n",
        "\n",
        "#   # meatada.json\n",
        "\n",
        "#   # verify if contains 'metadata.json' file\n",
        "#   path_json = os.path.join(datasetPath, currentpath, \"metadata.json\")\n",
        "#   if (os.path.exists(path_json)):\n",
        "#     with open(path_json) as f:\n",
        "#         data = json.load(f)\n",
        "#         metadatas.append(data)\n",
        "#   else:\n",
        "#     break\n",
        "\n",
        "#   # images\n",
        "\n",
        "#   # print('datasetPath:', datasetPath, '- currentpath:', currentpath)\n",
        "#   # path_images = os.path.join(datasetPath, currentpath)\n",
        "#   # print(path_images)\n",
        "\n",
        "#   filesname = read_files_names(datasetPath, currentpath)\n",
        "#   filesname.remove(\"metadata.json\")\n",
        "#   # print(filesname)\n",
        "\n",
        "#   # # verify if contains images at dir\n",
        "#   # if (len(filesname) == 0):\n",
        "#   #   break\n",
        "\n",
        "#   images = [read_image(datasetPath, currentpath, image_name) for image_name in filesname]\n",
        "#   # print(len(images))\n",
        "\n",
        "#   # data_augemntation\n",
        "#   for i, image_source in enumerate(images, start=0):\n",
        "#     for j, transformation in enumerate(list(transformations), start=0):\n",
        "\n",
        "#       image_transformed = transformations[transformation](image_source)\n",
        "#       image_transformed = img_as_ubyte(image_transformed)\n",
        "#       image_transformed = cv2.cvtColor(image_transformed, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#       cv2.imwrite(\n",
        "#           os.path.join(\n",
        "#               path_imgs,\n",
        "#               str(datetime.datetime.now().timestamp()).replace('.', '_') + \".jpg\"\n",
        "#           ),\n",
        "#           image_transformed\n",
        "#       )\n",
        "\n",
        "#   # # neurons for out of CNN\n",
        "#   n_neuron_out+=1\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7cQc13_Fot1a"
      },
      "source": [
        "# Separação do dataset em treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTjgQI9SwsZf"
      },
      "outputs": [],
      "source": [
        "n_neuronios_saida = 20\n",
        "\n",
        "labels_index = {    \n",
        "     0: \"amstel\"\n",
        "  ,  1: \"bavaria\"\n",
        "  ,  2: \"bohemia\"\n",
        "  ,  3: \"brahma\"\n",
        "  ,  4: \"colorado_appia_garrafa\"\n",
        "  ,  5: \"colorado_appia_lata\"\n",
        "  ,  6: \"colorado_indica_garrafa\"\n",
        "  ,  7: \"colorado_indica_lata\"\n",
        "  ,  8: \"coronita_long_neck\"\n",
        "  ,  9: \"heiniken\"\n",
        "  , 10: \"imperio\"\n",
        "  , 11: \"kaiser\"\n",
        "  , 12: \"original\"\n",
        "  , 13: \"skol_beats_gt\"\n",
        "  , 14: \"skol_beats_secret\"\n",
        "  , 15: \"skol_beats_senses\"\n",
        "  , 16: \"skol\"\n",
        "  , 17: \"sol\"\n",
        "  , 18: \"spaten\"\n",
        "  , 19: \"stella_artrois\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng-dK_SrkHY4"
      },
      "outputs": [],
      "source": [
        "train_data_X = np.concatenate(\n",
        "    (\n",
        "        train_data_amstel\n",
        "        , train_data_bavaria\n",
        "        , train_data_bohemia\n",
        "        , train_data_brahma\n",
        "        , train_data_colorado_appia_garrafa\n",
        "        , train_data_colorado_appia_lata\n",
        "        , train_data_colorado_indica_garrafa\n",
        "        , train_data_colorado_indica_lata\n",
        "        , train_data_coronita_long_neck\n",
        "        , train_data_heiniken\n",
        "        , train_data_imperio\n",
        "        , train_data_kaiser\n",
        "        , train_data_original\n",
        "        , train_data_skol_beats_gt\n",
        "        , train_data_skol_beats_secret\n",
        "        , train_data_skol_beats_senses\n",
        "        , train_data_skol\n",
        "        , train_data_sol\n",
        "        , train_data_spaten\n",
        "        , train_data_stella_artrois\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQaj4PxxkEpu"
      },
      "outputs": [],
      "source": [
        "train_data_y = to_categorical(\n",
        "    np.concatenate(\n",
        "        (\n",
        "              np.zeros(len(train_data_amstel)) # * 0\n",
        "            , np.ones(len(train_data_bavaria)) # * 1\n",
        "            , np.ones(len(train_data_bohemia)) * 2\n",
        "            , np.ones(len(train_data_brahma)) * 3\n",
        "            , np.ones(len(train_data_colorado_appia_garrafa)) * 4\n",
        "            , np.ones(len(train_data_colorado_appia_lata)) * 5\n",
        "            , np.ones(len(train_data_colorado_indica_garrafa)) * 6\n",
        "            , np.ones(len(train_data_colorado_indica_lata)) * 7\n",
        "            , np.ones(len(train_data_coronita_long_neck)) * 8\n",
        "            , np.ones(len(train_data_heiniken)) * 9\n",
        "            , np.ones(len(train_data_imperio)) * 10\n",
        "            , np.ones(len(train_data_kaiser)) * 11\n",
        "            , np.ones(len(train_data_original)) * 12\n",
        "            , np.ones(len(train_data_skol_beats_gt)) * 13\n",
        "            , np.ones(len(train_data_skol_beats_secret)) * 14\n",
        "            , np.ones(len(train_data_skol_beats_senses)) * 15\n",
        "            , np.ones(len(train_data_skol)) * 16\n",
        "            , np.ones(len(train_data_sol)) * 17\n",
        "            , np.ones(len(train_data_spaten)) * 18\n",
        "            , np.ones(len(train_data_stella_artrois)) * 19\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HK6tUX7oyzl"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( train_data_X, train_data_y, test_size=0.3, random_state=42 )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tPMDsVyfoTfN"
      },
      "source": [
        "# Modelagem e compilação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqOsJNxaoWlR"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "# ada_belief = AdaBeliefOptimizer(learning_rate=learning_rate)\n",
        "ada_belief = Adam(learning_rate=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IKUq8llocrB"
      },
      "outputs": [],
      "source": [
        "reset_seeds()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Extração de caracteristicas\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D( 64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D( 32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Achatamento\n",
        "model.add(Flatten())\n",
        "\n",
        "# classificadores\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense( 64, activation='relu'))\n",
        "# model.add(Dense(  3, activation='sigmoid'))\n",
        "model.add(Dense(  n_neuronios_saida, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCchCYe9opPS"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=ada_belief, loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QRXv8zElo5Gp"
      },
      "source": [
        "# Execução do treino do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tgivcFklNrC",
        "outputId": "492eba86-5371-4cf5-fb15-b0aaf892bdde"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "with mlflow.start_run(run_name='cnn_img_beer'):\n",
        "  reset_seeds()\n",
        "  hist = model.fit(X_train, y_train, epochs=25, validation_split=0.2)\n",
        "  model.evaluate(X_test, y_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ggdHik-T-VpT"
      },
      "source": [
        "# Predição com o modelo treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyGYXOAlfXTW"
      },
      "outputs": [],
      "source": [
        "# model.predict(X_test).argmax(axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8ywtOC4pMfD"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "def predic_img(i):\n",
        "\n",
        "  image_path = f'{datasetPath}/test/{i}.jpg'\n",
        "  \n",
        "  image_original = tf.keras.utils.load_img(\n",
        "      image_path,\n",
        "      grayscale=False, \n",
        "      color_mode='rgb', \n",
        "      target_size=None, \n",
        "      interpolation='nearest'\n",
        "  )\n",
        "\n",
        "  image_resized = image_original.resize(size)\n",
        "\n",
        "  image_prepared = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "  prediction = model.predict(image_prepared)\n",
        "\n",
        "  display(Image(image_path, width=50, height=50))\n",
        "\n",
        "  n_pos = prediction.argmax(axis=-1)[0]\n",
        "  \n",
        "  print(\n",
        "      'Prediction for item:', i\n",
        "      , '- position:', n_pos\n",
        "      , ' - label:', labels_index[n_pos]\n",
        "      , '\\n\\n'\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_6BiPgNpUNX"
      },
      "outputs": [],
      "source": [
        "# predic_img('0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGRF9xhm-cem"
      },
      "outputs": [],
      "source": [
        "# for i in range(0, 20):\n",
        "#   predic_img(i)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v0xJKaLL5kpt"
      },
      "source": [
        "# Salvar o modelo no google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efWssc_onV_J"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/PucMinas/projeto_integrado/' + 'cnn_trained_model_beer.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3kQr3NGfHo7q",
        "wZNCrDKJkN17",
        "XzOHMSw3kSR0",
        "K96b5_hBkZro",
        "3qlqc-P6rB1n",
        "nJSTbUZhkvZb",
        "-ubB3lRvjevF",
        "7cQc13_Fot1a",
        "tPMDsVyfoTfN",
        "QRXv8zElo5Gp",
        "ggdHik-T-VpT",
        "v0xJKaLL5kpt"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
