{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/Sentdex/130c225d90acec7c808b8ba5aba0eda1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mal/miniconda3/envs/project-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mal/miniconda3/envs/project-env/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/mal/miniconda3/envs/project-env/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from torch import autocast\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "          \"1965 Porsche 911\",\n",
    "          \"1975 Porsche 911\",\n",
    "          \"1985 Porsche 911\",\n",
    "          \"1995 Porsche 911\",\n",
    "          \"2005 Porsche 911 front\",\n",
    "          \"2015 Porsche 911\",\n",
    "          \"2020 Porsche 911\",\n",
    "          \"2020 Porsche 911 GT3 RS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:00<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# make sure you're logged in with `huggingface-cli login`\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    'CompVis/stable-diffusion-v1-4', \n",
    "    # revision='fp16',\n",
    "    # torch_dtype=torch.float16, \n",
    "    # use_auth_token=True\n",
    "    torch_dtype=torch.float32,\n",
    "    low_cpu_mem_usage=True,\n",
    "    safety_checker = None,\n",
    "    requires_safety_checker = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt,          \n",
    "    num_inference_steps=10, \n",
    "    samples=5,\n",
    "    seed=1024,\n",
    "    guidance_scale=7.5, \n",
    "    width=512, height=512\n",
    "):\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "    w = width//8*8\n",
    "    h = height//8*8\n",
    "    with autocast(\"cuda\"):\n",
    "        image = pipe(\n",
    "            prompt, \n",
    "            guidance_scale=7.5, \n",
    "            generator=generator,\n",
    "            width=w, height=h, \n",
    "            num_inference_steps=num_inference_steps)[0]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in prompts:\n",
    "\n",
    "#     prompt_orig = p \n",
    "#     if not os.path.exists(\"imagery\"):\n",
    "#         os.mkdir(\"imagery\")\n",
    "\n",
    "#     if not os.path.exists(f\"imagery/{prompt_orig}\"):\n",
    "#         os.mkdir(f\"imagery/{prompt_orig}/\")\n",
    "\n",
    "#     HM = 200\n",
    "#     for i in range(HM):\n",
    "#         print(f\"{i+1}/{HM}\")\n",
    "#         prompt_to_use = prompt_orig\n",
    "#         seed = random.randint(0, 10000)\n",
    "#         print(seed)\n",
    "#         image = infer(prompt_to_use, num_inference_steps=75, \n",
    "#                       seed=seed, width=512, height=512)\n",
    "#         image.save(f\"imagery/{prompt_to_use}/{seed}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 28/75 [04:35<07:43,  9.87s/it]"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for p in prompts:\n",
    "\n",
    "    HM = 200\n",
    "    \n",
    "    for i in range(HM):\n",
    "        \n",
    "        print(f\"{i+1}/{HM}\")\n",
    "\n",
    "        seed = random.randint(0, 10000)\n",
    "\n",
    "        image = infer(\n",
    "            p, \n",
    "            num_inference_steps=75, \n",
    "            seed=seed, \n",
    "            width=512, \n",
    "            height=512\n",
    "        )\n",
    "        \n",
    "        milis = int(datetime.now().timestamp() * 1000)\n",
    "\n",
    "        image.save(f\"../../images/stabilityai/sd_v21/out/{milis}{p}/{seed}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
